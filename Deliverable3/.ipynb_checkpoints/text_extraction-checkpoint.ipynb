{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanfordnlp\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/bf/5d2898febb6e993fcccd90484cba3c46353658511a41430012e901824e94/stanfordnlp-0.2.0-py3-none-any.whl (158kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (1.5.1)\n",
      "Requirement already satisfied: tqdm in /Users/msarica/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (4.36.1)\n",
      "Requirement already satisfied: protobuf in /Users/msarica/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (3.11.2)\n",
      "Requirement already satisfied: requests in /Users/msarica/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (2.22.0)\n",
      "Requirement already satisfied: numpy in /Users/msarica/anaconda3/lib/python3.7/site-packages (from stanfordnlp) (1.17.2)\n",
      "Requirement already satisfied: future in /Users/msarica/anaconda3/lib/python3.7/site-packages (from torch>=1.0.0->stanfordnlp) (0.17.1)\n",
      "Requirement already satisfied: six>=1.9 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from protobuf->stanfordnlp) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /Users/msarica/anaconda3/lib/python3.7/site-packages (from protobuf->stanfordnlp) (41.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/msarica/anaconda3/lib/python3.7/site-packages (from requests->stanfordnlp) (2.8)\n",
      "Installing collected packages: stanfordnlp\n",
      "Successfully installed stanfordnlp-0.2.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://stanfordnlp.github.io/stanfordnlp/\n",
    "# !pip install stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the default treebank \"en_ewt\" for language \"en\".\n",
      "Would you like to download the models for: en_ewt now? (Y/n)\n",
      "Y\n",
      "\n",
      "Default download directory: /Users/msarica/stanfordnlp_resources\n",
      "Hit enter to continue or type an alternate directory.\n",
      "\n",
      "\n",
      "Downloading models for: en_ewt\n",
      "Download location: /Users/msarica/stanfordnlp_resources/en_ewt_models.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235M/235M [00:21<00:00, 10.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete.  Models saved to: /Users/msarica/stanfordnlp_resources/en_ewt_models.zip\n",
      "Extracting models file for: en_ewt\n",
      "Cleaning up...Done.\n",
      "Use device: cpu\n",
      "---\n",
      "Loading: tokenize\n",
      "With settings: \n",
      "{'model_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt_tokenizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: pos\n",
      "With settings: \n",
      "{'model_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt_tagger.pt', 'pretrain_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "---\n",
      "Loading: lemma\n",
      "With settings: \n",
      "{'model_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt_lemmatizer.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n",
      "Building an attentional Seq2Seq model...\n",
      "Using a Bi-LSTM encoder\n",
      "Using soft attention for LSTM.\n",
      "Finetune all embeddings.\n",
      "[Running seq2seq lemmatizer with edit classifier]\n",
      "---\n",
      "Loading: depparse\n",
      "With settings: \n",
      "{'model_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt_parser.pt', 'pretrain_path': '/Users/msarica/stanfordnlp_resources/en_ewt_models/en_ewt.pretrain.pt', 'lang': 'en', 'shorthand': 'en_ewt', 'mode': 'predict'}\n"
     ]
    }
   ],
   "source": [
    "import stanfordnlp\n",
    "stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
    "nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n",
    "doc = nlp(\"Barack Obama was born in Hawaii.  He was elected president in 2008.\")\n",
    "doc.sentences[0].print_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
