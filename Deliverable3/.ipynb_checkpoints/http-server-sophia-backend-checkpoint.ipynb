{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def load_model(model_name, vector_name):\n",
    "    model = pickle.load(open(model_name, 'rb'))\n",
    "    vectorizer = pickle.load(open(vector_name, 'rb'))\n",
    "    return model, vectorizer\n",
    "\n",
    "def predict(sentence, model, vectorizer):\n",
    "    vector = vectorizer.transform([sentence])\n",
    "    prediction = model.predict(vector)[0]\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentence(device, model, initial_seed, vocab_to_int, int_to_vocab, top_k=5, length=50):\n",
    "    def get_word_index(w):\n",
    "        if w not in vocab_to_int: \n",
    "            return 0\n",
    "        return vocab_to_int[w]\n",
    "\n",
    "    model.eval()\n",
    "    # words = ['I', 'am']\n",
    "    words = initial_seed.split()\n",
    "\n",
    "    state_h, state_c = model.zero_state(1)\n",
    "    state_h = state_h.to(device)\n",
    "    state_c = state_c.to(device)\n",
    "    for w in words:\n",
    "        ix = torch.tensor([[get_word_index(w)]]).to(device)\n",
    "        # print(ix)\n",
    "        output, (state_h, state_c) = model(ix, (state_h, state_c))\n",
    "\n",
    "    _, top_ix = torch.topk(output[0], k=top_k)\n",
    "    choices = top_ix.tolist()\n",
    "    choice = np.random.choice(choices[0])\n",
    "\n",
    "    words.append(int_to_vocab[choice])\n",
    "    \n",
    "#     for _ in range(length):\n",
    "    while (len(words) > length and words[len(words)-1].strip().endswith('.')) == False:\n",
    "        ix = torch.tensor([[choice]]).to(device)\n",
    "        output, (state_h, state_c) = model(ix, (state_h, state_c))\n",
    "\n",
    "        _, top_ix = torch.topk(output[0], k=top_k)\n",
    "        choices = top_ix.tolist()\n",
    "        choice = np.random.choice(choices[0])\n",
    "        words.append(int_to_vocab[choice])\n",
    "\n",
    "    return (' '.join(words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class AutoRegressive(nn.Module):\n",
    "    def __init__(self, vocabulary_length, sequence_size, embedding_size, lstm_size):\n",
    "        super(AutoRegressive, self).__init__()\n",
    "        self.seq_size = sequence_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocabulary_length, \n",
    "            embedding_size\n",
    "            )\n",
    "        self.lstm = nn.LSTM(embedding_size,\n",
    "                            lstm_size,\n",
    "                            batch_first=False)\n",
    "        self.dense = nn.Linear(lstm_size, vocabulary_length)\n",
    "    \n",
    "    def forward(self, input, previous_state ): \n",
    "        embed = self.embedding(input)\n",
    "        output, state = self.lstm(embed, previous_state)\n",
    "        logits = self.dense(output)\n",
    "\n",
    "        return logits, state\n",
    "\n",
    "    def zero_state(self, batch_size):\n",
    "        return (torch.zeros(1, batch_size, self.lstm_size),\n",
    "                torch.zeros(1, batch_size, self.lstm_size))\n",
    "\n",
    "\n",
    "def _load_neural_network(model_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    checkpoint = torch.load(model_name, map_location=device)\n",
    "    words = checkpoint['words']\n",
    "    \n",
    "    model = AutoRegressive(len(words), 32, 64, 16)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    int_to_vocab = checkpoint['int_to_vocab']\n",
    "    vocab_to_int = checkpoint['vocab_to_int']\n",
    "    \n",
    "    return device, model, words, int_to_vocab, vocab_to_int\n",
    "\n",
    "def load_story_model():\n",
    "    file_name = 'story/story.pt'\n",
    "    device, model, words, int_to_vocab, vocab_to_int = _load_neural_network(file_name)\n",
    "    \n",
    "    def run_prediction(initial_words, min_length=50):\n",
    "        return predict_sentence(device, model, initial_words, vocab_to_int, int_to_vocab, length=min_length)\n",
    "    \n",
    "    return run_prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queen', 'grabbed']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict = load_story_model()\n",
    "# predict('queen grabbed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model_predict(model, vector):\n",
    "    m, v = load_model(model, vector)\n",
    "    \n",
    "    return lambda sentence: predict(sentence, m, v)\n",
    "    \n",
    "def load_model1():\n",
    "    model = 'model1/model.pickle'\n",
    "    vector = 'model1/vector.pickle'\n",
    "    return _load_model_predict(model, vector)\n",
    "\n",
    "def load_model2():\n",
    "    model = 'model2/model.pickle'\n",
    "    vector = 'model2/vector.pickle'\n",
    "    return _load_model_predict(model, vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stanfordnlp.github.io/stanfordnlp/\n",
    "# !pip install stanfordnlp\n",
    "\n",
    "import stanfordnlp\n",
    "# stanfordnlp.download('en')   # This downloads the English models for the neural pipeline\n",
    "nlp = stanfordnlp.Pipeline() # This sets up a default neural pipeline in English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def generate_time_units():\n",
    "    time_units = [\n",
    "        ('second', 1),\n",
    "        ('minute', 60),\n",
    "        ('hour', 3600),\n",
    "        ('day', 3600 * 24)\n",
    "    ];\n",
    "\n",
    "    times = []\n",
    "    for word, unit in time_units:\n",
    "        s = '\\w+(?=\\s'+ word +')'\n",
    "        r = re.compile(s, re.IGNORECASE)\n",
    "        times.append((r, unit))\n",
    "    return times\n",
    "\n",
    "times = generate_time_units()\n",
    "\n",
    "def timer(sentence):\n",
    "    def parse_int(value):\n",
    "        try:\n",
    "            return int(value.strip())\n",
    "        except: \n",
    "            return 0\n",
    "        \n",
    "    def convert_to_sec(regex_result, value_to_sec):\n",
    "        if regex_result == None:\n",
    "            return 0\n",
    "        \n",
    "        value = parse_int(regex_result[0])\n",
    "        return value * value_to_sec\n",
    "    \n",
    "    total = 0\n",
    "    for r, unit in times:\n",
    "        m = r.search(sentence)\n",
    "        total += convert_to_sec(m, unit)\n",
    "        \n",
    "    if total == 0:\n",
    "        m = re.search(r'\\d+', sentence)\n",
    "        total += convert_to_sec(m, 1)\n",
    "        \n",
    "    return total\n",
    "\n",
    "# timer('set a timer for 3 minutes 30 seconds')\n",
    "# timer('sadfa 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object(sentence, nlp=nlp):\n",
    "    doc = nlp(sentence)\n",
    "    # doc.sentences[0].print_dependencies()\n",
    "\n",
    "    objs = []\n",
    "    for i in doc.sentences[0].words:\n",
    "        # print(i.dependency_relation)\n",
    "        if(i.dependency_relation == 'obj'):\n",
    "            objs.append(i.text)\n",
    "    \n",
    "    return objs\n",
    "    \n",
    "\n",
    "# get_object('sophia set a timer for 5 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_story(sentence):\n",
    "    m = re.search(r'(?<=about\\s)[\\w\\s]*', sentence)\n",
    "    \n",
    "    initial = m[0]\n",
    "    return story_model(initial)\n",
    "    \n",
    "# tell_story('tell me a story about snow white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def time_now():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%I:%M %p\")\n",
    "    return f\"it is {current_time}\"\n",
    "\n",
    "# time_now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = load_model1()\n",
    "predict_category = load_model2()\n",
    "\n",
    "story_model = load_story_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(sentence):\n",
    "    # predict category\n",
    "    category = predict_category(sentence)\n",
    "    print(category)\n",
    "    \n",
    "    actions = {\n",
    "        'timer': lambda sent: timer(sent),\n",
    "        'shopping': lambda sent: get_object(sent),\n",
    "        'time_now': lambda sent: time_now(),\n",
    "        'story': lambda sent: tell_story(sent)\n",
    "    }\n",
    "    \n",
    "    if category in actions:\n",
    "        text = actions[category](sentence)\n",
    "    else:\n",
    "        text = None\n",
    "    \n",
    "    return category, text\n",
    "    \n",
    "# process('sophia can you add milk to my list')\n",
    "# process('set a timer for 5 ')\n",
    "# process('what time is it')\n",
    "# process('sophia please tell me a story about a witch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask\n",
    "from flask import jsonify, request\n",
    "from flask_cors import CORS\n",
    "\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "@app.route('/')\n",
    "def start():\n",
    "    sentence = request.args.get('sentence')\n",
    "    print(sentence)\n",
    "\n",
    "    category, text = process(sentence)\n",
    "    print(category, text)\n",
    "    return jsonify({\n",
    "        'category': category,\n",
    "        'text': text\n",
    "    })\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
